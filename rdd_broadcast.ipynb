{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"pyspark\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_raw = sc.parallelize([(0,1), (1,2), (2,5), (5,8), (7,8), (3,7), (3,4), (3,6)])\n",
    "btc = btc_raw.flatMap(lambda x: [x, (x[1], x[0])]).groupByKey().map(lambda x: (x[0], set(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version with broadcasting in the addEdge step on both Min_Selection_Step and Pruning_Step\n",
    "\n",
    "def Min_Selection_Step(G): #dictionary format RDD\n",
    "    v_min = G.map(lambda x: (x[0], min(x[1] | {x[0]})))\n",
    "    NN_G_u = G.map(lambda x: (x[0], (x[1] | {x[0]})))\n",
    "    \n",
    "    #Broadcasting\n",
    "    v_min_bc = sc.broadcast(dict(v_min.collect()))\n",
    "    addEdge = NN_G_u.map(lambda x: (x[0], (x[1], v_min_bc.value[x[0]]))).flatMap(lambda x: [(y, x[1][1]) for y in x[1][0]])\n",
    "    #Without broadcasting\n",
    "    #addEdge = NN_G_u.join(v_min).flatMap(lambda x: [(y, x[1][1]) for y in x[1][0]])\n",
    "    H = addEdge.groupByKey().map(lambda x: (x[0], set(x[1])))#.filter(lambda x: len(x[1]) > 1)\n",
    "    return H\n",
    "\n",
    "def Pruning_Step(H):\n",
    "    H_filtered = H.filter(lambda x: len(x[1]) > 1)\n",
    "    v_min = H_filtered.map(lambda x: (x[0], min(x[1])))\n",
    "    NN_H_u = H_filtered.map(lambda x: (x[0], x[1] - {min(x[1])} ))\n",
    "    \n",
    "    #Broadcasting\n",
    "    v_min_bc = sc.broadcast(dict(v_min.collect()))\n",
    "    addEdge2 = NN_H_u.map(lambda x: (x[0], (x[1], v_min_bc.value[x[0]]))).flatMap(lambda x: [(x[1][1], y) for y in x[1][0]])\n",
    "    #Without broadcasting\n",
    "    #addEdge2 = NN_H_u.join(v_min).flatMap(lambda x: [(x[1][1], y) for y in x[1][0]])\n",
    "    G = addEdge2.flatMap(lambda x: [x, (x[1], x[0])]).groupByKey().map(lambda x: (x[0], set(x[1])))\n",
    "    return G \n",
    "\n",
    "def cracker(G_i):\n",
    "    count = 0\n",
    "    while G_i.take(1):\n",
    "        count += 1\n",
    "        H_i = Min_Selection_Step(G_i)\n",
    "        G_i = Pruning_Step(H_i)\n",
    "        \n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version without broadcasting in the addEdge step on both Min_Selection_Step and Pruning_Step\n",
    "\n",
    "def Min_Selection_Step2(G): #dictionary format RDD\n",
    "    v_min = G.map(lambda x: (x[0], min(x[1] | {x[0]})))\n",
    "    NN_G_u = G.map(lambda x: (x[0], (x[1] | {x[0]})))\n",
    "    addEdge = v_min.join(NN_G_u)\n",
    "    H = addEdge.flatMap(lambda x: [(y, x[1][0]) for y in x[1][1]]).groupByKey().map(lambda x: (x[0], set(x[1])))\n",
    "    return H\n",
    "\n",
    "def Pruning_Step2(H):\n",
    "    H_filtered = H.filter(lambda x: len(x[1]) > 1)\n",
    "    v_min = H_filtered.map(lambda x: (x[0], min(x[1])))\n",
    "    NN_H_u = H_filtered.map(lambda x: (x[0], x[1] - {min(x[1])} ))\n",
    "    addEdge2 = v_min.join(NN_H_u).flatMap(lambda x: [(x[1][0], y) for y in x[1][1]])\n",
    "    G = addEdge2.flatMap(lambda x: [x, (x[1], x[0])]).groupByKey().map(lambda x: (x[0], set(x[1])))\n",
    "    return G \n",
    "\n",
    "def cracker2(G_i):\n",
    "    count = 0\n",
    "    while G_i.take(1):\n",
    "        count += 1\n",
    "        H_i = Min_Selection_Step2(G_i)\n",
    "        G_i = Pruning_Step2(H_i)\n",
    "        \n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 21.4 ms, total: 167 ms\n",
      "Wall time: 2.68 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cracker(btc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 300 ms, sys: 54.2 ms, total: 355 ms\n",
      "Wall time: 8.57 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cracker2(btc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
